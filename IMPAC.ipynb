{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import nilearn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiMapsMasker\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import nibabel as nib\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save matrix in a vector, removing its diagonal\n",
    "def reshape_no_diag(input_matrix):\n",
    "    L = np.size(input_matrix, axis = 0)\n",
    "    H_vec = np.reshape(input_matrix, (1, L*L))\n",
    "    for i in reversed(xrange(L)):\n",
    "        H_vec = np.delete(H_vec, i*L+i)\n",
    "    return H_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hitting_time_calculation(AtlasPath, ts, L):\n",
    "#     Inputs to hitting_time_calculation function:\n",
    "#     AtlasPath = \"path to nifti file including atlas image\", e.g. atlas_filename = \"/Volumes/MMP1_rois.nii\"\n",
    "#     ts = time_series\n",
    "#     L = atlas size\n",
    "\n",
    "    correlation_measure = ConnectivityMeasure(kind='partial correlation')\n",
    "    atlas_filename = AtlasPath\n",
    "    masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True,\n",
    "                               memory='nilearn_cache', verbose=5) \n",
    "        \n",
    "    correlation_matrix = correlation_measure.fit_transform([ts])[0]  \n",
    "    correlation_matrix = abs(correlation_matrix)\n",
    "    C_vec = np.reshape(correlation_matrix, (1, L*L))\n",
    "    thrshld = np.percentile(C_vec, 50)\n",
    "\n",
    "    np.fill_diagonal(correlation_matrix, 0)\n",
    "    \n",
    "    A_matrix = np.array(correlation_matrix)\n",
    "    A_matrix = A_matrix > thrshld\n",
    "    \n",
    "    D_matrix = np.zeros((L,L))\n",
    "    D_inv = np.zeros((L,L))\n",
    "    D_sqrt = np.zeros((L,L))\n",
    "    D_sqrt_inv = np.zeros((L,L))\n",
    "    for i in range(L):\n",
    "        D_matrix[i,i] = np.sum(A_matrix[i])\n",
    "        D_inv[i,i] = 1./D_matrix[i,i]\n",
    "        D_sqrt[i,i] = np.sqrt(D_matrix[i,i])\n",
    "        D_sqrt_inv[i,i] = 1./D_sqrt[i,i]\n",
    "\n",
    "    p_matrix = np.dot(D_inv, A_matrix)\n",
    "    \n",
    "    # Graph Laplacian\n",
    "    eye_matrix = np.eye(L,L)\n",
    "    eye_P = eye_matrix - p_matrix\n",
    "\n",
    "    G_Lap = np.dot(D_sqrt,eye_P)\n",
    "    G_Lap_n = np.dot(G_Lap, D_sqrt_inv)\n",
    "\n",
    "    [eig_val, eig_vec] = np.linalg.eigh(G_Lap_n)\n",
    "\n",
    "    H = np.zeros((L,L))\n",
    "    d = np.sum(D_matrix)\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            deg_i = D_matrix[i,i]\n",
    "            deg_j = D_matrix[j,j]\n",
    "            for k in range(L):\n",
    "                if eig_val[k] != min(eig_val):\n",
    "                    t_i = (eig_vec[i,k]*eig_vec[i,k])/deg_i\n",
    "                    t_j = (eig_vec[j,k]*eig_vec[j,k])/deg_j\n",
    "                    t_ij = (eig_vec[i,k]*eig_vec[j,k])/np.sqrt(deg_i*deg_j)\n",
    "                    H[i,j] = H[i,j] + d*(1./(eig_val[k]))*(t_j-t_ij)\n",
    "\n",
    "    H = np.transpose(H)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extraction(H):\n",
    "    H_vec = reshape_no_diag(H)\n",
    "    H_mean = np.mean(H_vec)\n",
    "    H_var = np.var(H_vec)\n",
    "    H_skew = scipy.stats.skew(H_vec)\n",
    "    H_kurtosis = scipy.stats.kurtosis(H_vec)\n",
    "    H_Q10 = np.percentile(H_vec,10)\n",
    "    H_Q90 = np.percentile(H_vec,90)\n",
    "    H_medskew = H_Q90 - H_Q10\n",
    "    H_median = np.median(H_vec)  \n",
    "    H_kelly = H_Q90 + H_Q10 - 2*H_median\n",
    "    return H_mean, H_var, H_medskew, H_kurtosis, H_skew, H_median, H_kelly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import astropy.table as table\n",
    "import astropy.units as u\n",
    "import sys\n",
    "from astropy.table import Table, Column, MaskedColumn\n",
    "from astropy.io import ascii \n",
    "import openpyxl\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = {'subject_id': [], 'mean': [], 'median': [], 'var': [], 'skew': [], 'kelly': [], 'kurtosis': [], 'medskew': []}\n",
    "\n",
    "for ts, subject_id, original_confound in zip(time_series,\n",
    "                                             dataset.subject_id,\n",
    "                                             dataset.motion):\n",
    "    ### calculate hitting time \n",
    "#     AtlasPath = \"path to nifti file including atlas image\"\n",
    "    H = hitting_time_calculation(AtlasPath, ts, L)\n",
    "    \n",
    "    ### calculate hitting time properties\n",
    "    H_mean, H_var, H_medskew, H_kurtosis, H_skew, H_median, H_kelly = feature_extraction(H)\n",
    "    \n",
    "    ### writing the extracted features\n",
    "    dataset['subject_id'].append(subject_id)\n",
    "    dataset['mean'].append(H_mean)\n",
    "    dataset['median'].append(H_median)\n",
    "    dataset['var'].append(H_var)\n",
    "    dataset['medskew'].append(H_medskew)\n",
    "    dataset['kurtosis'].append(H_kurtosis)\n",
    "    dataset['kelly'].append(H_kelly)\n",
    "    dataset['skew'].append(H_skew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
